{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29337422",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa24763",
   "metadata": {},
   "source": [
    "## 关于半个 Attention 矩阵的问题，\n",
    "训练和推理过程要分开来看，\n",
    "训练过程，为了锻炼模型的预测下一个 token 的能力，自然只会让模型只“看到”其之前的 token，这是生成任务与翻译任务的区别，\n",
    "而推理过程中，理论上来讲，用户输入的内容，是可以双向计算 Attention 的，\n",
    "论文《What Language Model Architecture and Pretraining  Objective Work Best for Zero-Shot Generalization》对三中机制\n",
    "* Encoder-Decoder\n",
    "* Decoder only （就是 Causal）\n",
    "* Decoder only + 特殊的 Attention，就是输入部分，双向计算，生成部分单向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0ef5529d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "         [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]]),\n",
       " tensor([[[-1.5107, -1.2339,  0.3342, -1.0417, -0.1341, -0.4620,  0.3182,\n",
       "           -0.4359,  0.9680, -2.0363],\n",
       "          [ 1.5530, -1.3971, -0.9803,  0.3606,  0.2158, -0.5770, -0.9402,\n",
       "            0.0410,  0.4711,  1.4336],\n",
       "          [-0.2862,  0.3326,  0.3727,  0.1386,  0.8457, -0.1808, -0.8695,\n",
       "           -0.8945, -1.4147, -1.5214],\n",
       "          [ 1.2778,  2.2090, -1.2422,  2.3947, -1.0153, -1.0643, -0.9961,\n",
       "           -0.1322, -0.2122,  1.2000],\n",
       "          [-1.2890, -0.4229, -0.5525, -0.0515, -0.3217, -0.9903,  1.2266,\n",
       "           -0.3242,  0.5241,  0.5959],\n",
       "          [-0.3074, -0.1412,  1.3545, -0.5640, -1.0317,  0.1701, -0.7377,\n",
       "            0.1274,  0.2804, -1.3673],\n",
       "          [ 0.7267,  0.9915,  0.6307, -0.9482, -0.1192, -2.2511,  2.6040,\n",
       "           -0.2426,  1.7323,  2.2242],\n",
       "          [ 1.9599,  0.7850, -2.6602, -2.3031, -0.7164,  1.7576,  0.2898,\n",
       "            0.1852,  0.0312, -0.1744],\n",
       "          [-0.5686,  0.1932, -0.4152,  1.0574, -0.2014,  0.2329, -1.0604,\n",
       "           -1.0154,  0.9756, -0.0990],\n",
       "          [ 0.3359,  0.0906,  0.7106,  0.2242,  0.6170, -0.7808,  0.1397,\n",
       "            0.0783,  0.0216, -0.7661]]]),\n",
       " tensor([[[-1.5107, -0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
       "           -0.0000,  0.0000, -0.0000],\n",
       "          [ 1.5530, -1.3971, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "            0.0000,  0.0000,  0.0000],\n",
       "          [-0.2862,  0.3326,  0.3727,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           -0.0000, -0.0000, -0.0000],\n",
       "          [ 1.2778,  2.2090, -1.2422,  2.3947, -0.0000, -0.0000, -0.0000,\n",
       "           -0.0000, -0.0000,  0.0000],\n",
       "          [-1.2890, -0.4229, -0.5525, -0.0515, -0.3217, -0.0000,  0.0000,\n",
       "           -0.0000,  0.0000,  0.0000],\n",
       "          [-0.3074, -0.1412,  1.3545, -0.5640, -1.0317,  0.1701, -0.0000,\n",
       "            0.0000,  0.0000, -0.0000],\n",
       "          [ 0.7267,  0.9915,  0.6307, -0.9482, -0.1192, -2.2511,  2.6040,\n",
       "           -0.0000,  0.0000,  0.0000],\n",
       "          [ 1.9599,  0.7850, -2.6602, -2.3031, -0.7164,  1.7576,  0.2898,\n",
       "            0.1852,  0.0000, -0.0000],\n",
       "          [-0.5686,  0.1932, -0.4152,  1.0574, -0.2014,  0.2329, -1.0604,\n",
       "           -1.0154,  0.9756, -0.0000],\n",
       "          [ 0.3359,  0.0906,  0.7106,  0.2242,  0.6170, -0.7808,  0.1397,\n",
       "            0.0783,  0.0216, -0.7661]]]),\n",
       " tensor([[[-1.5107],\n",
       "          [ 0.1558],\n",
       "          [ 0.4192],\n",
       "          [ 4.6393],\n",
       "          [-2.6376],\n",
       "          [-0.5198],\n",
       "          [ 1.6343],\n",
       "          [-0.7021],\n",
       "          [-0.8018],\n",
       "          [ 0.6710]]]),\n",
       " tensor([[[ 1.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000, -0.0000,\n",
       "            0.0000, -0.0000,  0.0000],\n",
       "          [ 9.9664, -8.9664, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "            0.0000,  0.0000,  0.0000],\n",
       "          [-0.6828,  0.7935,  0.8892,  0.0000,  0.0000, -0.0000, -0.0000,\n",
       "           -0.0000, -0.0000, -0.0000],\n",
       "          [ 0.2754,  0.4762, -0.2678,  0.5162, -0.0000, -0.0000, -0.0000,\n",
       "           -0.0000, -0.0000,  0.0000],\n",
       "          [ 0.4887,  0.1603,  0.2095,  0.0195,  0.1220,  0.0000, -0.0000,\n",
       "            0.0000, -0.0000, -0.0000],\n",
       "          [ 0.5915,  0.2717, -2.6059,  1.0850,  1.9849, -0.3272,  0.0000,\n",
       "           -0.0000, -0.0000,  0.0000],\n",
       "          [ 0.4447,  0.6067,  0.3859, -0.5802, -0.0730, -1.3774,  1.5933,\n",
       "           -0.0000,  0.0000,  0.0000],\n",
       "          [-2.7913, -1.1181,  3.7888,  3.2802,  1.0203, -2.5033, -0.4128,\n",
       "           -0.2638, -0.0000,  0.0000],\n",
       "          [ 0.7091, -0.2409,  0.5179, -1.3187,  0.2511, -0.2905,  1.3225,\n",
       "            1.2663, -1.2168,  0.0000],\n",
       "          [ 0.5005,  0.1350,  1.0590,  0.3342,  0.9196, -1.1636,  0.2081,\n",
       "            0.1168,  0.0321, -1.1417]]]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = torch.tril(torch.ones(10, 10))\n",
    "attention = torch.randn(1, 10, 10)\n",
    "after = attention * mask\n",
    "#attention_ = attention_.masked_fill(mask == 0, float('-inf'))\n",
    "sums = after.sum(-1, keepdim=True)#-1是最里面那一层，keepDim=true 表示保持在原来的维度上，每一行加起来还是一行，而不是一列，一列的就缩成一行了，缩的方向就不对了\n",
    "after2 = after / sums #保证每行加起来是1，也算做了softmax\n",
    "mask,attention,after,sums,after2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "250d1ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " tensor([[[-1.5107,    -inf,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf,    -inf,    -inf],\n",
       "          [ 1.5530, -1.3971,    -inf,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf,    -inf,    -inf],\n",
       "          [-0.2862,  0.3326,  0.3727,    -inf,    -inf,    -inf,    -inf,\n",
       "              -inf,    -inf,    -inf],\n",
       "          [ 1.2778,  2.2090, -1.2422,  2.3947,    -inf,    -inf,    -inf,\n",
       "              -inf,    -inf,    -inf],\n",
       "          [-1.2890, -0.4229, -0.5525, -0.0515, -0.3217,    -inf,    -inf,\n",
       "              -inf,    -inf,    -inf],\n",
       "          [-0.3074, -0.1412,  1.3545, -0.5640, -1.0317,  0.1701,    -inf,\n",
       "              -inf,    -inf,    -inf],\n",
       "          [ 0.7267,  0.9915,  0.6307, -0.9482, -0.1192, -2.2511,  2.6040,\n",
       "              -inf,    -inf,    -inf],\n",
       "          [ 1.9599,  0.7850, -2.6602, -2.3031, -0.7164,  1.7576,  0.2898,\n",
       "            0.1852,    -inf,    -inf],\n",
       "          [-0.5686,  0.1932, -0.4152,  1.0574, -0.2014,  0.2329, -1.0604,\n",
       "           -1.0154,  0.9756,    -inf],\n",
       "          [ 0.3359,  0.0906,  0.7106,  0.2242,  0.6170, -0.7808,  0.1397,\n",
       "            0.0783,  0.0216, -0.7661]]]),\n",
       " tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.9503, 0.0497, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.2088, 0.3877, 0.4035, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.1498, 0.3803, 0.0121, 0.4578, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0866, 0.2060, 0.1809, 0.2986, 0.2279, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0969, 0.1144, 0.5106, 0.0750, 0.0470, 0.1562, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0960, 0.1251, 0.0872, 0.0180, 0.0412, 0.0049, 0.6275, 0.0000,\n",
       "           0.0000, 0.0000],\n",
       "          [0.3882, 0.1199, 0.0038, 0.0055, 0.0267, 0.3171, 0.0731, 0.0658,\n",
       "           0.0000, 0.0000],\n",
       "          [0.0526, 0.1127, 0.0614, 0.2676, 0.0760, 0.1173, 0.0322, 0.0337,\n",
       "           0.2466, 0.0000],\n",
       "          [0.1185, 0.0927, 0.1723, 0.1060, 0.1569, 0.0388, 0.0974, 0.0916,\n",
       "           0.0865, 0.0394]]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attention = torch.randn(1, 10, 10)\n",
    "mask = torch.tril(torch.ones(100, 100))  #固定参数的缓存\n",
    "attention3 = attention.masked_fill(mask[:10, :10] == 0, float('-inf'))\n",
    "result = F.softmax(attention3, dim=-1)\n",
    "mask, attention3, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a6c9833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-inf\n",
      "-inf\n"
     ]
    }
   ],
   "source": [
    "print(float('-inf'))\n",
    "print(-torch.inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9129de34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [2., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [2., 2., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [2., 0., 0.,  ..., 2., 0., 0.],\n",
       "         [2., 2., 2.,  ..., 2., 2., 0.],\n",
       "         [2., 0., 2.,  ..., 0., 0., 0.]]),\n",
       " tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropout attention weights\n",
    "layer = nn.Dropout(p=0.5)\n",
    "layer\n",
    "out = layer(mask)\n",
    "out,mask # Dropout 在丢弃一部分神经元的同时，会对保留下来的神经元进行缩放，即乘以 1/(1-p)，以保持其期望值不变,如果p=0.5，那么保留下来的神经元会乘以2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5d58c033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-4.,  1.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([-2.0, 1])\n",
    "w = torch.tensor([[2, 1.0], [0, 3]])\n",
    "y = torch.matmul(x, w)\n",
    "y #x = torch.tensor([-12.0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed5aa05",
   "metadata": {},
   "source": [
    "# 表达式要包括含\\$\\$之间\n",
    "\n",
    "$$\\left[ \n",
    "\\begin{array}{cc}\n",
    "        1 & 0 \\\\\n",
    "        0 & 2\n",
    "    \\end{array}\n",
    "\\right]\n",
    "\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{array}\n",
    "\\right] $$\n",
    "\n",
    "\n",
    "$$ \\left[ \n",
    "\\begin{array}{cc}\n",
    "        1 & 0 \\\\\n",
    "        0 & 2\n",
    "    \\end{array}\n",
    "\\right]\n",
    "\n",
    "\\left[\n",
    "\\begin{array}{c}\n",
    "x_1 \\\\\n",
    "x_2\n",
    "\\end{array}\n",
    "\\right] $$\n",
    "\n",
    "$x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}$\n",
    "$F = G{Mm \\over r^2}$ \n",
    "$\\alpha, \\beta, \\gamma, \\Gamma, \\pi$\n",
    "\n",
    "\n",
    "$\\sqrt{x}, \\sqrt[3]{x}, \\sqrt[n]{x}$\n",
    "\n",
    "$\\left[ \n",
    "\\begin{matrix}\n",
    "   a & b & c\\\\\n",
    "   d & e & f\n",
    "\\end{matrix}\n",
    "\n",
    "$$f(n) = \n",
    "\\begin{cases}\n",
    "n/2, & \\text{if } n \\text{ is even} \\\\\n",
    "3n+1, & \\text{if } n \\text{ is odd}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\\left( \\frac{x}{y} \\right), \\quad \n",
    "\n",
    "\\left[ f(x) \\right]\n",
    "\n",
    ", \\quad \\left| x \\right|$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "380d0486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.,  3.])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = torch.tensor([[2, 0.0], [1, 3]])\n",
    "y1 = torch.matmul(x, w1)\n",
    "y1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b47217",
   "metadata": {},
   "source": [
    "#\n",
    "向量[-2,1]与矩阵 $ \\left[ \\begin{array}{cc} 2,1\\\\0,3 \\end{array} \\right] $ 相乘，"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d9f69",
   "metadata": {},
   "source": [
    "# 点积，到底是什么？\n",
    "按照Transformer 的架构的原理，用点积的结果表示两个向量的相似度或者说相关性，那按照这个逻辑，在点积之前就应该计算 softmax，这样点积的结果才更加能够表示两个 token 之间的关系，而实际 Transformer 架构中是先计算 Attention，再进行 softmax，这样做是否有问题，Transformer 的架构在这点上是否有调整的可能？\n",
    "\n",
    "点积能够比较两个向量的特征，这个特征不是一种概率分布，就是在各个维度上的取值，\n",
    "而 softmax，是一种量化的手段，模型的某些层级上可以去“考虑”某些维度是重要的，某些维度是不重要的，softmax 不是用来调整模型的特征的取值，只能选择而不是调整改变\n",
    "\n",
    "\n",
    "大语言模型是\"概率模型\"，不是因为其内部表示是概率分布，而是因为：\n",
    "训练目标：最小化基于概率的损失函数（交叉熵）\n",
    "输出形式：最终输出是词汇表上的概率分布\n",
    "生成过程：基于概率进行序列生成\n",
    "内部机制：使用注意力权重的概率分布来加权信息\n",
    "\n",
    "\n",
    "Normalization（归一化）的目的是为了改变数据的分布，使其更利于模型训练。而 Softmax 的目的是将一个向量“压缩”为概率分布，使其所有元素之和为1。\n",
    "Normalization 是一个数据预处理/特征工程的技术，它通过对原始数据进行线性或非线性变换，将数据缩放到一个特定的尺度或范围内（如 [0, 1] 或 均值为0，方差为1），但不改变数据本身的分布结构（线性变换不改变）。\n",
    "\n",
    "\n",
    "加速模型收敛：在梯度下降中，如果特征尺度差异巨大，损失函数的等高线会是椭球状，导致优化路径呈“之字形”，收敛缓慢。归一化后，等高线更接近圆形，优化路径更直接。\n",
    "\n",
    "\n",
    "Softmax 是一个数学函数，它接收一个任意实数的向量（通常是神经网络的原始输出，称为 logits），并将其“压缩”成一个概率分布。这个概率分布的所有元素都在 (0, 1) 之间，且所有元素之和为 1。\n",
    "\n",
    "\n",
    "Normalization是针对不同数据的上的同一个特征，\n",
    "softmax 一般是针对同一个数据的不同特征，"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "index-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
