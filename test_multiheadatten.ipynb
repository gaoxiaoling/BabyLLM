{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f7792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n",
      "tensor([[[-1.5649, -1.3532, -4.0740,  0.8929, -8.4856, -1.0724, -0.0855,\n",
      "          -0.9880,  3.2151,  3.1751,  3.7551, -7.2735,  1.3397, -3.0716,\n",
      "          -2.7595, -2.1480],\n",
      "         [ 3.4132, -6.3484,  4.6959, -0.7620, -1.7537, -0.9969, -0.0724,\n",
      "          -2.7878,  3.8748, -1.3810,  1.1899,  5.7457, -1.0007,  3.5734,\n",
      "           1.1297, -1.3047],\n",
      "         [-1.8012,  5.1732, -6.5868,  2.6120, -1.6539, -0.9734,  0.0325,\n",
      "          -2.7399,  3.9427, -1.1633,  0.8765,  5.8409, -1.0593,  3.6650,\n",
      "           1.1376, -1.3424],\n",
      "         [-1.4840, -1.4230, -3.9500,  0.9074, -2.6856,  0.3176,  0.9264,\n",
      "           1.3010,  3.2149,  3.1754,  3.7550, -7.2733,  1.1633, -2.0135,\n",
      "          -1.7948, -1.5702]],\n",
      "\n",
      "        [[-0.7083,  6.1169,  0.1217, -5.4605,  2.8015,  0.4397,  0.5819,\n",
      "          -0.8836, -2.8862, -1.1686,  1.5834, -3.1698, -0.3299,  2.9014,\n",
      "           0.2904, -0.2892],\n",
      "         [-3.6727,  4.5478, -2.4831, -0.8912, -0.4585, -0.9909,  3.0340,\n",
      "           0.6181,  0.3662,  3.5849, -0.5144,  1.7115, -1.8987,  2.4878,\n",
      "          -0.8122,  0.8774],\n",
      "         [-0.7083,  6.1169,  0.1217, -5.4605, -0.4410, -0.9488,  2.8891,\n",
      "           0.5679,  0.4126,  3.6512, -0.5440,  1.7810, -1.8986,  2.4878,\n",
      "          -0.8121,  0.8774],\n",
      "         [-5.8475,  3.4447, -4.4205,  2.4352,  0.3766,  0.6178, -2.3382,\n",
      "          -1.2798, -0.1683, -1.9028,  1.2363, -0.1650, -1.8985,  2.4872,\n",
      "          -0.8125,  0.8768]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from MultiHeadAttention import MultiHeadAttention\n",
    "\n",
    "\n",
    "\n",
    "input = torch.tensor([[[-0.0030, -0.3975, -0.5519, -2.1307,  2.0991,  2.1801, -0.8764,1.5101],\n",
    "         [-0.6975, -2.2657,  0.3965,  0.0505, -2.0436,  0.4248, -0.2923,-0.4120],\n",
    "         [-1.6629, -1.4232,  0.2857, -0.4816, -1.4639, -1.6402,  0.1611,-0.1676],\n",
    "         [-0.6369,  0.6567, -1.5477, -0.2093,  0.7766,  2.5461,  0.2027,-0.1022]],\n",
    "        [[-0.7106,  0.9046, -1.8254,  1.5167,  0.6793, -0.0608, -1.3678,1.6743],\n",
    "         [-0.7040,  0.7689,  0.9518, -0.1849,  0.0027, -1.6395,  0.5792,0.5842],\n",
    "         [-1.1012,  2.7022,  0.0623, -1.1669, -1.5534, -0.3910,  0.4203,0.1466],\n",
    "         [-0.9392, -0.4035, -0.4383, -1.0112, -0.3384,  0.4169,  0.7527,-0.8412]]])#torch.randn(2, 4, 8)  # (batch_size, seq_length, embed_size)\n",
    "print(input.shape)\n",
    "mla = MultiHeadAttention(d_model=8, num_heads=4, d_head=4, dropout=0)\n",
    "out = mla(input)\n",
    "print(out)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "index-tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
